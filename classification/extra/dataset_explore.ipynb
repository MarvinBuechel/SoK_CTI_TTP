{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import BoschTechniquesDataset, TramDataset\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_json(\"../datasets/tram_train.json\"),  pd.read_json(\"../datasets/tram_test.json\")], ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, \n",
    "                       'display.max_columns', None, \n",
    "                       'display.max_colwidth', None):  # Set max_colwidth to None\n",
    "    filtered_df = df[df['labels'].apply(lambda x: 'T1112' in x or 'T1547.001' in x)]\n",
    "    filtered_df = filtered_df[filtered_df['sentence'].apply(lambda x: 'attack' in x)]\n",
    "    display(filtered_df[['sentence', 'labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAS0= [x for x in dftest.labels.explode().unique().tolist() if str(x).startswith(\"T\") and not (str(x).startswith(\"TA\"))]\n",
    "len(TAS0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAS1= [x for x in df.labels.explode().unique().tolist() if str(x).startswith(\"T\") and not (str(x).startswith(\"TA\"))]\n",
    "len(TAS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(TAS0).difference(TAS1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(TAS0).intersection(TAS1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop, \"Choose reference dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just because the Dataset class needs a tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "df_train = pd.read_json(\"../datasets/bosch_train.json\")\n",
    "df_test = pd.read_json(\"../datasets/bosch_test.json\")\n",
    "dataset_train = BoschTechniquesDataset(df_train, tokenizer)\n",
    "dataset_test = BoschTechniquesDataset(df_test, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "df_train = pd.read_json(\"../datasets/tram_train.json\")\n",
    "df_test = pd.read_json(\"../datasets/tram_test.json\")\n",
    "dataset_train = TramDataset(df_train, tokenizer)\n",
    "dataset_test = TramDataset(df_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for item in dataset_train:\n",
    "    labels.append(item['labels'].cpu().numpy())\n",
    "for item in dataset_test:\n",
    "    labels.append(item['labels'].cpu().numpy())\n",
    "labels = np.array(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cumsum = labels.sum(axis=0)\n",
    "l_cumsum, l_cumsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cumsum = labels.sum(axis=0)\n",
    "q05 = np.quantile(l_cumsum, 0.5)\n",
    "mean = np.mean(l_cumsum)\n",
    "q05, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_above_mean = np.where(l_cumsum > mean, l_cumsum, 0)\n",
    "l_above_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_above_median = np.where(l_cumsum > q05, l_cumsum, 0)\n",
    "l_above_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtop_10 = sorted(l_cumsum, reverse=True)[9]\n",
    "l_top10 = np.where(l_cumsum >= vtop_10, l_cumsum, 0)\n",
    "l_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.delete(l_above_median, np.where(l_above_median == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.delete(l_above_mean, np.where(l_above_mean == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.delete(l_top10, np.where(l_top10 == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop, \"CHOOSE DATASET!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import BOSCH_TECHNIQUES_LABELS, TRAM_TECHNIQUES_LABELS\n",
    "labels = TRAM_TECHNIQUES_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: l for i, l in enumerate(labels)}\n",
    "label_mean = [id2label[x] for x in np.nonzero(l_above_mean)[0]]\n",
    "label_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_median = [id2label[x] for x in np.nonzero(l_above_median)[0]]\n",
    "label_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_top10 = [id2label[x] for x in np.nonzero(l_top10)[0]]\n",
    "label_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
