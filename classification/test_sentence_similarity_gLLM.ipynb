{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/mitre_embeddings.pickle\", \"rb\") as f:\n",
    "    mitre_embeddings_w_id = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/nvidia-mitre-embeddings.pickle\", \"rb\") as f:\n",
    "    mitre_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/nvidia-tram-train-embeddings.pickle\", \"rb\") as f:\n",
    "    tram_train_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/nvidia-tram-test-embeddings.pickle\", \"rb\") as f:\n",
    "    tram_test_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/nvidia-bosch-train-embeddings.pickle\", \"rb\") as f:\n",
    "    bosch_train_embeddings = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/nvidia-bosch-test-embeddings.pickle\", \"rb\") as f:\n",
    "    bosch_test_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't find ttp id 637\n"
     ]
    }
   ],
   "source": [
    "ttp_ids = list(mitre_embeddings_w_id.keys())\n",
    "i = 0\n",
    "mitre_embeddings_fix = {}\n",
    "for batch in mitre_embeddings:\n",
    "    for emb in batch:\n",
    "        try:\n",
    "            mitre_embeddings_fix[ttp_ids[i]] = emb\n",
    "        except:\n",
    "            print(\"can't find ttp id %s\" % i)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda:0\"\n",
    "tram_train_embeddings = {k.item(): F.normalize(v.to(device), p=2, dim=0) for k,v in tram_train_embeddings.items()}\n",
    "tram_test_embeddings = {k: F.normalize(v.to(device), p=2, dim=0) for k,v in tram_test_embeddings.items()}\n",
    "\n",
    "bosch_train_embeddings = {k.item(): F.normalize(v.to(device), p=2, dim=0) for k,v in bosch_train_embeddings.items()}\n",
    "bosch_test_embeddings = {k: F.normalize(v.to(device), p=2, dim=0) for k,v in bosch_test_embeddings.items()}\n",
    "\n",
    "mitre_embeddings_fix = {k: v.to(device) for k,v in mitre_embeddings_fix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0007, -0.0003, -0.0106,  ...,  0.0073,  0.0012,  0.0085],\n",
       "        [ 0.0103, -0.0072, -0.0098,  ..., -0.0055,  0.0033,  0.0030],\n",
       "        [-0.0071, -0.0036, -0.0189,  ...,  0.0305,  0.0080,  0.0192],\n",
       "        ...,\n",
       "        [ 0.0077,  0.0140,  0.0342,  ...,  0.0055, -0.0175,  0.0068],\n",
       "        [ 0.0034,  0.0177,  0.0283,  ..., -0.0124,  0.0017,  0.0082],\n",
       "        [-0.0005,  0.0029, -0.0014,  ...,  0.0169, -0.0038,  0.0150]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttp_embeddings = torch.vstack(list(mitre_embeddings_fix.values()))\n",
    "ttp_embeddings = F.normalize(ttp_embeddings, p=2, dim=1)\n",
    "ttp_embeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import TRAM_TECHNIQUES_LABELS, BOSCH_TECHNIQUES_LABELS\n",
    "\n",
    "tram_bosch = sorted(list(set(BOSCH_TECHNIQUES_LABELS).union(TRAM_TECHNIQUES_LABELS)))\n",
    "\n",
    "ttp_ids_bosch = [i for i,t in enumerate(ttp_ids) if t in BOSCH_TECHNIQUES_LABELS]\n",
    "ttp_ids_tram = [i for i,t in enumerate(ttp_ids) if t in TRAM_TECHNIQUES_LABELS]\n",
    "ttp_ids_all = [i for i,t in enumerate(ttp_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:27<01:27, 87.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_set=tram_t best_f1=0.172825459730935 best_tau=0.48684210526315785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [04:59<00:00, 149.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_set=all_mitre best_f1=0.17282545973093494 best_tau=0.48684210526315785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tram_results = {}\n",
    "\n",
    "ids_per_label_set = {\n",
    "    \"tram_t\": ttp_ids_tram,\n",
    "    \"bosch_t\": ttp_ids_bosch,\n",
    "    \"all_mitre\": ttp_ids_all # this contains ids\n",
    "}\n",
    "\n",
    "labels_per_label_set = {\n",
    "    \"tram_t\": TRAM_TECHNIQUES_LABELS,\n",
    "    \"bosch_t\": BOSCH_TECHNIQUES_LABELS,\n",
    "    \"all_mitre\": ttp_ids # this contains labels\n",
    "}\n",
    "\n",
    "df = pd.read_json(\"datasets/tram_train.json\")\n",
    "\n",
    "for label_set in tqdm([\"tram_t\", \"all_mitre\"]):\n",
    "    \n",
    "    labels = labels_per_label_set[label_set]\n",
    "    label_ids = ids_per_label_set[label_set]\n",
    "\n",
    "    lb = MultiLabelBinarizer()\n",
    "    lb.fit([labels])\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_tau = 0.5\n",
    "\n",
    "    for tau in np.linspace(0.25, 0.75, num=20):\n",
    "\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for i, emb in tram_train_embeddings.items():\n",
    "\n",
    "            # Compute similarities\n",
    "            similarities = emb @ ttp_embeddings.T  # Resulting shape: (number_of_embeddings,)\n",
    "            \n",
    "            # Create a mask based on ttp_ids_bosch_all\n",
    "            mask = torch.zeros(similarities.shape, dtype=torch.bool)  # Match the shape of similarities\n",
    "            mask[label_ids] = True  # Assume ttp_ids_bosch_all contains valid indices\n",
    "\n",
    "            # Set values not in the mask to 0\n",
    "            similarities[~mask] = 0  # Directly apply the mask to the 1D tensor\n",
    "            indices_above_threshold = torch.where(similarities > tau)[0]\n",
    "            ttp_values = [ttp_ids[i] for i in indices_above_threshold]\n",
    "            tram_labels = df.iloc[i].labels\n",
    "            tram_labels = [l for l in tram_labels if l in labels]\n",
    "            all_labels.append(tram_labels)\n",
    "            all_preds.append(ttp_values)\n",
    "\n",
    "        y_true = lb.transform(all_labels)\n",
    "        y_pred = lb.transform(all_preds)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0.0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_tau = tau\n",
    "        \n",
    "    tram_results[label_set] = {\n",
    "        \"best_f1\": best_f1,\n",
    "        \"best_tau\": best_tau\n",
    "    }\n",
    "    \n",
    "    print(\"label_set=%s best_f1=%s best_tau=%s\" % (label_set, best_f1, best_tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AnnoCTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:24<00:24, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_set=bosch_t best_f1=0.18945444005115686 best_tau=0.4342105263157895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:13<00:00, 36.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_set=all_mitre best_f1=0.18967108320730455 best_tau=0.4342105263157895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "bosch_results = {}\n",
    "\n",
    "df = pd.read_json(\"datasets/bosch_train.json\")\n",
    "\n",
    "for label_set in tqdm([\"bosch_t\", \"all_mitre\"]):\n",
    "    \n",
    "    labels = labels_per_label_set[label_set]\n",
    "    label_ids = ids_per_label_set[label_set]\n",
    "\n",
    "    lb = MultiLabelBinarizer()\n",
    "    lb.fit([labels])\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_tau = 0.5\n",
    "\n",
    "    for tau in np.linspace(0.25, 0.75, num=20):\n",
    "\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for i, emb in bosch_train_embeddings.items():\n",
    "\n",
    "            # Compute similarities\n",
    "            similarities = emb @ ttp_embeddings.T  # Resulting shape: (number_of_embeddings,)\n",
    "            \n",
    "            # Create a mask based on ttp_ids_bosch_all\n",
    "            mask = torch.zeros(similarities.shape, dtype=torch.bool)  # Match the shape of similarities\n",
    "            mask[label_ids] = True  # Assume ttp_ids_bosch_all contains valid indices\n",
    "\n",
    "            # Set values not in the mask to 0\n",
    "            similarities[~mask] = 0  # Directly apply the mask to the 1D tensor\n",
    "            indices_above_threshold = torch.where(similarities > tau)[0]\n",
    "            ttp_values = [ttp_ids[i] for i in indices_above_threshold]\n",
    "            bosch_labels = df.iloc[i].labels\n",
    "            bosch_labels = [l for l in bosch_labels if l in labels]\n",
    "            all_labels.append(bosch_labels)\n",
    "            all_preds.append(ttp_values)\n",
    "\n",
    "        y_true = lb.transform(all_labels)\n",
    "        y_pred = lb.transform(all_preds)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0.0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_tau = tau\n",
    "        \n",
    "    bosch_results[label_set] = {\n",
    "        \"best_f1\": best_f1,\n",
    "        \"best_tau\": best_tau\n",
    "    }\n",
    "    \n",
    "    print(\"label_set=%s best_f1=%s best_tau=%s\" % (label_set, best_f1, best_tau))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tram_results = {'tram_t': {'best_f1': np.float64(0.172825459730935),\n",
    "#   'best_tau': np.float64(0.48684210526315785)},\n",
    "#  'all_mitre': {'best_f1': np.float64(0.17282545973093494),\n",
    "#   'best_tau': np.float64(0.48684210526315785)}}\n",
    "\n",
    "# bosch_results = {'bosch_t': {'best_f1': np.float64(0.18945444005115686),\n",
    "#   'best_tau': np.float64(0.4342105263157895)},\n",
    "#  'all_mitre': {'best_f1': np.float64(0.18967108320730455),\n",
    "#   'best_tau': np.float64(0.4342105263157895)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "tram_out = {}\n",
    "\n",
    "df = pd.read_json(\"datasets/tram_test.json\")\n",
    "\n",
    "for label_set in tqdm([\"tram_t\", \"all_mitre\"]):\n",
    "    \n",
    "    labels = labels_per_label_set[label_set]\n",
    "    label_ids = ids_per_label_set[label_set]\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    lb = MultiLabelBinarizer()\n",
    "    lb.fit([labels])\n",
    "\n",
    "    tau = tram_results[label_set][\"best_tau\"]\n",
    "    tram_out[label_set] = {}\n",
    "\n",
    "    for doc_name, df_doc in df.groupby(\"doc_title\"):\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for idx, row in df_doc.iterrows():\n",
    "\n",
    "            tram_labels = [l for l in row.labels if l in labels]\n",
    "            emb = tram_test_embeddings[list(tram_test_embeddings.keys())[idx]].to(device)\n",
    "            # Compute similarities\n",
    "            similarities = emb @ ttp_embeddings.T  # Resulting shape: (number_of_embeddings,)\n",
    "            \n",
    "            # Create a mask based on ttp_ids_bosch_all\n",
    "            mask = torch.zeros(similarities.shape, dtype=torch.bool)  # Match the shape of similarities\n",
    "            mask[label_ids] = True  # Assume ttp_ids_bosch_all contains valid indices\n",
    "\n",
    "            # Set values not in the mask to 0\n",
    "            similarities[~mask] = 0  # Directly apply the mask to the 1D tensor\n",
    "            indices_above_threshold = torch.where(similarities > tau)[0]\n",
    "            ttp_values = [ttp_ids[i] for i in indices_above_threshold]\n",
    "\n",
    "            all_labels.extend(tram_labels)\n",
    "            all_preds.extend(ttp_values)\n",
    "\n",
    "        tram_out[label_set][doc_name] = {\n",
    "            \"labels\": list(set(all_labels)),\n",
    "            \"preds\": list(set(all_preds))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "bosch_out = {}\n",
    "\n",
    "df = pd.read_json(\"datasets/bosch_test.json\")\n",
    "\n",
    "for label_set in tqdm([\"bosch_t\", \"all_mitre\"]):\n",
    "    \n",
    "    labels = labels_per_label_set[label_set]\n",
    "    label_ids = ids_per_label_set[label_set]\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    lb = MultiLabelBinarizer()\n",
    "    lb.fit([labels])\n",
    "\n",
    "    tau = bosch_results[label_set][\"best_tau\"]\n",
    "    bosch_out[label_set] = {}\n",
    "\n",
    "    for doc_name, df_doc in df.groupby(\"document\"):\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for idx, row in df_doc.iterrows():\n",
    "\n",
    "            bosch_labels = [l for l in row.labels if l in labels]\n",
    "\n",
    "            emb = bosch_test_embeddings[idx]\n",
    "            # Compute similarities\n",
    "            similarities = emb @ ttp_embeddings.T  # Resulting shape: (number_of_embeddings,)\n",
    "            \n",
    "            # Create a mask based on ttp_ids_bosch_all\n",
    "            mask = torch.zeros(similarities.shape, dtype=torch.bool)  # Match the shape of similarities\n",
    "            mask[label_ids] = True  # Assume ttp_ids_bosch_all contains valid indices\n",
    "\n",
    "            # Set values not in the mask to 0\n",
    "            similarities[~mask] = 0  # Directly apply the mask to the 1D tensor\n",
    "            indices_above_threshold = torch.where(similarities > tau)[0]\n",
    "            ttp_values = [ttp_ids[i] for i in indices_above_threshold]\n",
    "\n",
    "            all_labels.extend(bosch_labels)\n",
    "            all_preds.extend(ttp_values)\n",
    "\n",
    "        bosch_out[label_set][doc_name] = {\n",
    "            \"labels\": list(set(all_labels)),\n",
    "            \"preds\": list(set(all_preds))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_common import calc_results_per_document\n",
    "\n",
    "output = {\n",
    "    \"model_name\": [],\n",
    "    \"dataset_name\": [],\n",
    "    \"label_set\": [],\n",
    "    \"f1\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": []\n",
    "}\n",
    "\n",
    "for dataset, out in zip([\"tram\", \"bosch\"], [tram_out, bosch_out]):\n",
    "    for label_set in out:\n",
    "        results_df = calc_results_per_document(out[label_set])\n",
    "        f1 = results_df.f1.mean()\n",
    "        accuracy = results_df.accuracy.mean()\n",
    "        precision = results_df.precision.mean()\n",
    "        recall = results_df.recall.mean()\n",
    "        output[\"model_name\"].append(\"nvidia-embed\")\n",
    "        output[\"dataset_name\"].append(dataset)\n",
    "        output[\"label_set\"].append(label_set)\n",
    "        output[\"f1\"].append(f1)\n",
    "        output[\"accuracy\"].append(accuracy)\n",
    "        output[\"precision\"].append(precision)\n",
    "        output[\"recall\"].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>label_set</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nvidia-embed</td>\n",
       "      <td>bosch</td>\n",
       "      <td>all_mitre</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5.85</td>\n",
       "      <td>63.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nvidia-embed</td>\n",
       "      <td>bosch</td>\n",
       "      <td>bosch_t</td>\n",
       "      <td>29.51</td>\n",
       "      <td>24.17</td>\n",
       "      <td>62.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nvidia-embed</td>\n",
       "      <td>tram</td>\n",
       "      <td>all_mitre</td>\n",
       "      <td>11.37</td>\n",
       "      <td>7.85</td>\n",
       "      <td>64.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nvidia-embed</td>\n",
       "      <td>tram</td>\n",
       "      <td>tram_t</td>\n",
       "      <td>45.69</td>\n",
       "      <td>41.59</td>\n",
       "      <td>64.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name dataset_name  label_set     f1  precision  recall\n",
       "3  nvidia-embed        bosch  all_mitre   9.50       5.85   63.19\n",
       "2  nvidia-embed        bosch    bosch_t  29.51      24.17   62.45\n",
       "1  nvidia-embed         tram  all_mitre  11.37       7.85   64.94\n",
       "0  nvidia-embed         tram     tram_t  45.69      41.59   64.94"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(output).sort_values(by=\"f1\")\n",
    "final_df.f1 = (final_df.f1 * 100).round(2)\n",
    "final_df.precision = (final_df.precision * 100).round(2)\n",
    "final_df.recall = (final_df.recall * 100).round(2)\n",
    "final_df = final_df.sort_values(by=[\"dataset_name\", \"label_set\"], ascending=[True, True])\n",
    "\n",
    "final_df[[\"model_name\", \"dataset_name\", \"label_set\", \"f1\", \"precision\", \"recall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
